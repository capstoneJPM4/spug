{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a77a6af",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d6f065c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch_geometric.utils import dense_to_sparse\n",
    "from torch_geometric_temporal.signal import DynamicGraphTemporalSignal\n",
    "from torch_geometric_temporal.signal import temporal_signal_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350a5cab",
   "metadata": {},
   "source": [
    "## utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3eea0cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_and_split(data):\n",
    "    # Normalize node features and transform data type\n",
    "    data.x = normalize(data.x, axis=1, norm='max')\n",
    "    data.x = torch.from_numpy(data.x).to(torch.float64)\n",
    "    data.y = data.y.apply_(lambda x:  1 if (x > 0) else 0) # Change y into {0, 1} for binary classification\n",
    "    data.y = data.y.to(torch.float64)    \n",
    "    data.edge_attr = data.edge_attr.to(torch.double)\n",
    "\n",
    "\n",
    "    # Split into train/test set\n",
    "#    split = nodeSplit(split=\"train_rest\", num_splits = 1, num_val = 0.0, num_test= 0.2)\n",
    "#    masked_data = split(data)\n",
    "\n",
    "#    print(\"Training samples:\", torch.sum(masked_data.train_mask).item())\n",
    "#    print(\"Validation samples:\", torch.sum(masked_data.val_mask ).item())\n",
    "#    print(\"Test samples:\", torch.sum(masked_data.test_mask ).item())\n",
    "    print_basic_info(data)\n",
    "    return data\n",
    "\n",
    "def print_basic_info(data):\n",
    "    print()\n",
    "    print(data)\n",
    "    print('===========================================================================================================')\n",
    "\n",
    "    print(f'Number of nodes: {data.num_nodes}')\n",
    "    print(f'Number of edges: {data.num_edges}')\n",
    "    print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
    "    print(f'Has isolated nodes: {data.has_isolated_nodes()}')\n",
    "    print(f'Has self-loops: {data.has_self_loops()}')\n",
    "    print(f'Is undirected: {data.is_undirected()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5286dd63",
   "metadata": {},
   "source": [
    "## get and split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd96e224",
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2016\n",
    "month = 10\n",
    "month_year = []\n",
    "for i in range(59):\n",
    "    if month == 13:\n",
    "        month = 1\n",
    "        year += 1\n",
    "    month_year.append([year, month])\n",
    "    month += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87de3e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_df = pd.read_csv(\n",
    "            os.path.join('../data/raw',\"stock\",\"raw.csv\"),\n",
    "            usecols=[\"ticker_symbol\", \"Date\", \"Close\"],\n",
    "            parse_dates=[\"Date\"],\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "212f9962",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Close</th>\n",
       "      <th>ticker_symbol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-10-03</td>\n",
       "      <td>28.129999</td>\n",
       "      <td>aapl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-10-04</td>\n",
       "      <td>28.250000</td>\n",
       "      <td>aapl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-10-05</td>\n",
       "      <td>28.262501</td>\n",
       "      <td>aapl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-10-06</td>\n",
       "      <td>28.472500</td>\n",
       "      <td>aapl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-10-07</td>\n",
       "      <td>28.514999</td>\n",
       "      <td>aapl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date      Close ticker_symbol\n",
       "0 2016-10-03  28.129999          aapl\n",
       "1 2016-10-04  28.250000          aapl\n",
       "2 2016-10-05  28.262501          aapl\n",
       "3 2016-10-06  28.472500          aapl\n",
       "4 2016-10-07  28.514999          aapl"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd76be85",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_y = []\n",
    "mat_list = []\n",
    "for yr_month in month_year:\n",
    "    yr = yr_month[0]\n",
    "    month = yr_month[1]\n",
    "    directory = '../data/raw/twitter/'\n",
    "    mat_list.append(np.load(directory+str(yr)+'_'+str(month)+'.npy'))\n",
    "    ######################################################## \n",
    "    # prepare X (change this if you want to add SEC emb, etc.)\n",
    "    ########################################################\n",
    "    curr = stock_df[(stock_df.Date.dt.year == yr) & (stock_df.Date.dt.month == month)]\n",
    "    X = curr.pivot_table(\n",
    "            index=\"Date\", columns=\"ticker_symbol\", values=\"Close\"\n",
    "        ).values.T\n",
    "    x_logret = np.diff(np.log(X))\n",
    "    col_zeros = np.zeros((X.shape[0], 1))\n",
    "    x_normalized = np.append(col_zeros, x_logret, 1)\n",
    "    X_tensor = torch.tensor(x_normalized)\n",
    "    X_tensor = X_tensor.to(torch.float64)\n",
    "    \n",
    "    ########################################################\n",
    "    # prepare y (change this if you want to change labels)\n",
    "    ########################################################\n",
    "    if month == 12:\n",
    "        y_yr = yr+1\n",
    "        y_month = 1\n",
    "    else:\n",
    "        y_yr = yr\n",
    "        y_month = month + 1\n",
    "    \n",
    "    nxt = stock_df[(stock_df.Date.dt.year == y_yr) & (stock_df.Date.dt.month == y_month)]\n",
    "    y = nxt.pivot_table(\n",
    "            index=\"Date\", columns=\"ticker_symbol\", values=\"Close\"\n",
    "        ).values.T\n",
    "    y = (y.mean(1) - X.mean(1)) / X.mean(1)\n",
    "    y_tensor = torch.tensor(y)\n",
    "    X_y.append((X_tensor,y_tensor))\n",
    "    \n",
    "edge_idx = []\n",
    "edge_att = []\n",
    "for i in range(59):\n",
    "    edge_index, edge_attr = dense_to_sparse(torch.from_numpy(mat_list[i]))\n",
    "    edge_idx.append(edge_index)\n",
    "    edge_att.append(edge_attr)\n",
    "edge_indices = [i.numpy() for i in edge_idx]\n",
    "edge_weights = [i.numpy() for i in edge_att]\n",
    "features = []\n",
    "targets = []\n",
    "for i in range(59):\n",
    "    features.append(normalize(X_y[i][0].numpy(), axis=1, norm='max'))\n",
    "    #features.append(X_y[i][0].numpy())\n",
    "    targets.append([1 if a > 0 else 0 for a in X_y[i][1].numpy()])\n",
    "targets = np.asarray(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa7c8233",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_features = []\n",
    "for i in features:\n",
    "    padded_features.append(np.pad(i, [(0, 0), (0, 23-i.shape[1])], 'mean'))\n",
    "\n",
    "comp_emb = []\n",
    "for fp in sorted(os.listdir(\"../data/raw/sec/\")):\n",
    "    full_path = os.path.join(\"../data/raw\", \"sec\", fp)\n",
    "    if fp.split(\".\")[-1]=='npy':\n",
    "        comp_emb.append(torch.from_numpy(np.load(full_path)))\n",
    "comp_emb = torch.stack(comp_emb)\n",
    "comp_emb = np.asarray([comp_emb.numpy() for i in range(59)])\n",
    "padded_features = np.concatenate((padded_features, comp_emb), axis = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ef128fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch_geometric_temporal'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/rh/qn7_sn9x3y52f8x9fksn9djw0000gn/T/ipykernel_60657/2502502590.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch_geometric_temporal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDynamicGraphTemporalSignal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch_geometric_temporal'"
     ]
    }
   ],
   "source": [
    "temporal_signal = DynamicGraphTemporalSignal(edge_indices = edge_indices , \\\n",
    "                                             edge_weights = edge_weights, \\\n",
    "                                             features = padded_features, \\\n",
    "                                             targets = targets)\n",
    "\n",
    "train_dataset, test_dataset = temporal_signal_split(temporal_signal, train_ratio=0.8)b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b082d1",
   "metadata": {},
   "source": [
    "## model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4ed1598",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric_temporal.nn.recurrent import DCRNN\n",
    "from torch_geometric_temporal import TemporalConv\n",
    "from torch_geometric_temporal import EvolveGCNO\n",
    "from torch_geometric_temporal import GConvGRU\n",
    "class RecurrentGCN(torch.nn.Module):\n",
    "    def __init__(self, node_features):\n",
    "        super(RecurrentGCN, self).__init__()\n",
    "        self.evol = EvolveGCNO(node_features)\n",
    "        self.recurrent = DCRNN(node_features, 16, 1)\n",
    "        self.conv = GConvGRU(node_features, 64, 3)\n",
    "        #self.linear = torch.nn.Linear(16, 1)\n",
    "        self.linear = torch.nn.Linear(64, 2)\n",
    "        self.dropout = torch.nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight):\n",
    "#        h = self.recurrent(x, edge_index, edge_weight)\n",
    "#        h = self.dropout(h)\n",
    "        h = self.conv(x, edge_index, edge_weight)\n",
    "        #h = self.dropout(h)\n",
    "        h = F.relu(h)\n",
    "        h = self.linear(h)\n",
    "        h = torch.sigmoid(h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84eb169f",
   "metadata": {},
   "source": [
    "## model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7830058",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "model = RecurrentGCN(node_features = 791)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "model.train()\n",
    "\n",
    "for epoch in tqdm(range(200)):\n",
    "    loss = 0\n",
    "    for time, snapshot in enumerate(train_dataset):\n",
    "        y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n",
    "        loss += torch.nn.CrossEntropyLoss()(y_hat, snapshot.y.long())\n",
    "#        loss += torch.mean((y_hat-snapshot.y)**2)\n",
    "#        loss = loss / (time+1)\n",
    "        \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3114d6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_l = []\n",
    "model.eval()\n",
    "cost = 0\n",
    "for time, snapshot in enumerate(test_dataset):\n",
    "    y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n",
    "    #cost = cost + torch.mean((y_hat-snapshot.y)**2)\n",
    "    y_hat_l.append(y_hat)\n",
    "#cost = cost / (time+1)\n",
    "#cost = cost.item()\n",
    "#print(\"MSE: {:.4f}\".format(cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702afb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_l = [list(np.squeeze(i.detach().numpy())) for i in y_hat_l]\n",
    "y_hat_l = [z for y in y_hat_l for z in y]\n",
    "y_hat_l = [y[1] for y in y_hat_l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0010a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_label = []\n",
    "for time, snapshot in enumerate(test_dataset):\n",
    "    true_label.append(list(snapshot.y.detach().numpy()))\n",
    "true_label = [int(z) for y in true_label for z in y]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75137ce0",
   "metadata": {},
   "source": [
    "## experiment results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef9d40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = true_label\n",
    "pred = np.array(y_hat_l)\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y, pred)\n",
    "metrics.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d08b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_list = [1 if x > 0.5 else 0 for x in y_hat_l]\n",
    "y_true = true_label\n",
    "target_names = ['class 0', 'class 1']\n",
    "print(metrics.classification_report(y_true, y_hat_list, target_names=target_names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
