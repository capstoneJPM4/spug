{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use pytorch geometric temporal, make sure you have torch 1.9.0 installed (uninstall 1.10.0 before)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9.0+cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-1.9.0+cpu.html\n",
    "!pip install torch-sparse -f https://pytorch-geometric.com/whl/torch-1.9.0+cpu.html\n",
    "!pip install torch-cluster -f https://pytorch-geometric.com/whl/torch-1.9.0+cpu.html\n",
    "!pip install torch-spline-conv -f https://pytorch-geometric.com/whl/torch-1.9.0+cpu.html\n",
    "!pip install torch-geometric\n",
    "!pip install torch-geometric-temporal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def transform_and_split(data):\n",
    "    # Normalize node features and transform data type\n",
    "    data.x = normalize(data.x, axis=1, norm='max')\n",
    "    data.x = torch.from_numpy(data.x).to(torch.float64)\n",
    "    data.y = data.y.apply_(lambda x:  1 if (x > 0) else 0) # Change y into {0, 1} for binary classification\n",
    "    data.y = data.y.to(torch.float64)    \n",
    "    data.edge_attr = data.edge_attr.to(torch.double)\n",
    "\n",
    "\n",
    "    # Split into train/test set\n",
    "#    split = nodeSplit(split=\"train_rest\", num_splits = 1, num_val = 0.0, num_test= 0.2)\n",
    "#    masked_data = split(data)\n",
    "\n",
    "#    print(\"Training samples:\", torch.sum(masked_data.train_mask).item())\n",
    "#    print(\"Validation samples:\", torch.sum(masked_data.val_mask ).item())\n",
    "#    print(\"Test samples:\", torch.sum(masked_data.test_mask ).item())\n",
    "    print_basic_info(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_basic_info(data):\n",
    "    print()\n",
    "    print(data)\n",
    "    print('===========================================================================================================')\n",
    "\n",
    "    print(f'Number of nodes: {data.num_nodes}')\n",
    "    print(f'Number of edges: {data.num_edges}')\n",
    "    print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
    "    print(f'Has isolated nodes: {data.has_isolated_nodes()}')\n",
    "    print(f'Has self-loops: {data.has_self_loops()}')\n",
    "    print(f'Is undirected: {data.is_undirected()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get and split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data(x=[29, 61], edge_index=[2, 400], edge_attr=[400], y=[29])\n",
      "===========================================================================================================\n",
      "Number of nodes: 29\n",
      "Number of edges: 400\n",
      "Average node degree: 13.79\n",
      "Has isolated nodes: False\n",
      "Has self-loops: True\n",
      "Is undirected: True\n"
     ]
    }
   ],
   "source": [
    "path = \"../data/processed/twitter/2018_q1.pt\" # Customize...\n",
    "dataset = torch.load(path)\n",
    "data = dataset[0]\n",
    "transformed_data = transform_and_split(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric_temporal.dataset import ChickenpoxDatasetLoader\n",
    "\n",
    "loader = ChickenpoxDatasetLoader()\n",
    "\n",
    "dataset = loader.get_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.edge_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../data/processed/twitter/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "quarter = ['2016_q4']\n",
    "for i in range(2017, 2022):\n",
    "    for j in range(1, 5):\n",
    "        if i == 2021 and j == 4: break\n",
    "        quarter.append(str(i)+'_q'+str(j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2016_q4',\n",
       " '2017_q1',\n",
       " '2017_q2',\n",
       " '2017_q3',\n",
       " '2017_q4',\n",
       " '2018_q1',\n",
       " '2018_q2',\n",
       " '2018_q3',\n",
       " '2018_q4',\n",
       " '2019_q1',\n",
       " '2019_q2',\n",
       " '2019_q3',\n",
       " '2019_q4',\n",
       " '2020_q1',\n",
       " '2020_q2',\n",
       " '2020_q3',\n",
       " '2020_q4',\n",
       " '2021_q1',\n",
       " '2021_q2',\n",
       " '2021_q3']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quarter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = []\n",
    "for i in quarter:\n",
    "    paths.append(path+i+'.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/processed/twitter/2016_q4.pt',\n",
       " '../data/processed/twitter/2017_q1.pt',\n",
       " '../data/processed/twitter/2017_q2.pt',\n",
       " '../data/processed/twitter/2017_q3.pt',\n",
       " '../data/processed/twitter/2017_q4.pt',\n",
       " '../data/processed/twitter/2018_q1.pt',\n",
       " '../data/processed/twitter/2018_q2.pt',\n",
       " '../data/processed/twitter/2018_q3.pt',\n",
       " '../data/processed/twitter/2018_q4.pt',\n",
       " '../data/processed/twitter/2019_q1.pt',\n",
       " '../data/processed/twitter/2019_q2.pt',\n",
       " '../data/processed/twitter/2019_q3.pt',\n",
       " '../data/processed/twitter/2019_q4.pt',\n",
       " '../data/processed/twitter/2020_q1.pt',\n",
       " '../data/processed/twitter/2020_q2.pt',\n",
       " '../data/processed/twitter/2020_q3.pt',\n",
       " '../data/processed/twitter/2020_q4.pt',\n",
       " '../data/processed/twitter/2021_q1.pt',\n",
       " '../data/processed/twitter/2021_q2.pt',\n",
       " '../data/processed/twitter/2021_q3.pt']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data(x=[29, 63], edge_index=[2, 760], edge_attr=[760], y=[29])\n",
      "===========================================================================================================\n",
      "Number of nodes: 29\n",
      "Number of edges: 760\n",
      "Average node degree: 26.21\n",
      "Has isolated nodes: False\n",
      "Has self-loops: True\n",
      "Is undirected: True\n",
      "\n",
      "Data(x=[29, 62], edge_index=[2, 312], edge_attr=[312], y=[29])\n",
      "===========================================================================================================\n",
      "Number of nodes: 29\n",
      "Number of edges: 312\n",
      "Average node degree: 10.76\n",
      "Has isolated nodes: False\n",
      "Has self-loops: True\n",
      "Is undirected: True\n",
      "\n",
      "Data(x=[29, 63], edge_index=[2, 400], edge_attr=[400], y=[29])\n",
      "===========================================================================================================\n",
      "Number of nodes: 29\n",
      "Number of edges: 400\n",
      "Average node degree: 13.79\n",
      "Has isolated nodes: False\n",
      "Has self-loops: True\n",
      "Is undirected: True\n",
      "\n",
      "Data(x=[29, 63], edge_index=[2, 552], edge_attr=[552], y=[29])\n",
      "===========================================================================================================\n",
      "Number of nodes: 29\n",
      "Number of edges: 552\n",
      "Average node degree: 19.03\n",
      "Has isolated nodes: False\n",
      "Has self-loops: True\n",
      "Is undirected: True\n",
      "\n",
      "Data(x=[29, 63], edge_index=[2, 805], edge_attr=[805], y=[29])\n",
      "===========================================================================================================\n",
      "Number of nodes: 29\n",
      "Number of edges: 805\n",
      "Average node degree: 27.76\n",
      "Has isolated nodes: False\n",
      "Has self-loops: True\n",
      "Is undirected: True\n",
      "\n",
      "Data(x=[29, 61], edge_index=[2, 400], edge_attr=[400], y=[29])\n",
      "===========================================================================================================\n",
      "Number of nodes: 29\n",
      "Number of edges: 400\n",
      "Average node degree: 13.79\n",
      "Has isolated nodes: False\n",
      "Has self-loops: True\n",
      "Is undirected: True\n",
      "\n",
      "Data(x=[29, 64], edge_index=[2, 616], edge_attr=[616], y=[29])\n",
      "===========================================================================================================\n",
      "Number of nodes: 29\n",
      "Number of edges: 616\n",
      "Average node degree: 21.24\n",
      "Has isolated nodes: False\n",
      "Has self-loops: True\n",
      "Is undirected: True\n",
      "\n",
      "Data(x=[29, 63], edge_index=[2, 585], edge_attr=[585], y=[29])\n",
      "===========================================================================================================\n",
      "Number of nodes: 29\n",
      "Number of edges: 585\n",
      "Average node degree: 20.17\n",
      "Has isolated nodes: False\n",
      "Has self-loops: True\n",
      "Is undirected: True\n",
      "\n",
      "Data(x=[29, 63], edge_index=[2, 805], edge_attr=[805], y=[29])\n",
      "===========================================================================================================\n",
      "Number of nodes: 29\n",
      "Number of edges: 805\n",
      "Average node degree: 27.76\n",
      "Has isolated nodes: False\n",
      "Has self-loops: True\n",
      "Is undirected: True\n",
      "\n",
      "Data(x=[29, 61], edge_index=[2, 552], edge_attr=[552], y=[29])\n",
      "===========================================================================================================\n",
      "Number of nodes: 29\n",
      "Number of edges: 552\n",
      "Average node degree: 19.03\n",
      "Has isolated nodes: False\n",
      "Has self-loops: True\n",
      "Is undirected: True\n",
      "\n",
      "Data(x=[29, 63], edge_index=[2, 552], edge_attr=[552], y=[29])\n",
      "===========================================================================================================\n",
      "Number of nodes: 29\n",
      "Number of edges: 552\n",
      "Average node degree: 19.03\n",
      "Has isolated nodes: False\n",
      "Has self-loops: True\n",
      "Is undirected: True\n",
      "\n",
      "Data(x=[29, 64], edge_index=[2, 672], edge_attr=[672], y=[29])\n",
      "===========================================================================================================\n",
      "Number of nodes: 29\n",
      "Number of edges: 672\n",
      "Average node degree: 23.17\n",
      "Has isolated nodes: False\n",
      "Has self-loops: True\n",
      "Is undirected: True\n",
      "\n",
      "Data(x=[29, 64], edge_index=[2, 777], edge_attr=[777], y=[29])\n",
      "===========================================================================================================\n",
      "Number of nodes: 29\n",
      "Number of edges: 777\n",
      "Average node degree: 26.79\n",
      "Has isolated nodes: False\n",
      "Has self-loops: True\n",
      "Is undirected: True\n",
      "\n",
      "Data(x=[29, 62], edge_index=[2, 480], edge_attr=[480], y=[29])\n",
      "===========================================================================================================\n",
      "Number of nodes: 29\n",
      "Number of edges: 480\n",
      "Average node degree: 16.55\n",
      "Has isolated nodes: False\n",
      "Has self-loops: True\n",
      "Is undirected: True\n",
      "\n",
      "Data(x=[29, 63], edge_index=[2, 585], edge_attr=[585], y=[29])\n",
      "===========================================================================================================\n",
      "Number of nodes: 29\n",
      "Number of edges: 585\n",
      "Average node degree: 20.17\n",
      "Has isolated nodes: False\n",
      "Has self-loops: True\n",
      "Is undirected: True\n",
      "\n",
      "Data(x=[29, 64], edge_index=[2, 697], edge_attr=[697], y=[29])\n",
      "===========================================================================================================\n",
      "Number of nodes: 29\n",
      "Number of edges: 697\n",
      "Average node degree: 24.03\n",
      "Has isolated nodes: False\n",
      "Has self-loops: True\n",
      "Is undirected: True\n",
      "\n",
      "Data(x=[29, 64], edge_index=[2, 805], edge_attr=[805], y=[29])\n",
      "===========================================================================================================\n",
      "Number of nodes: 29\n",
      "Number of edges: 805\n",
      "Average node degree: 27.76\n",
      "Has isolated nodes: False\n",
      "Has self-loops: True\n",
      "Is undirected: True\n",
      "\n",
      "Data(x=[29, 61], edge_index=[2, 616], edge_attr=[616], y=[29])\n",
      "===========================================================================================================\n",
      "Number of nodes: 29\n",
      "Number of edges: 616\n",
      "Average node degree: 21.24\n",
      "Has isolated nodes: False\n",
      "Has self-loops: True\n",
      "Is undirected: True\n",
      "\n",
      "Data(x=[29, 63], edge_index=[2, 720], edge_attr=[720], y=[29])\n",
      "===========================================================================================================\n",
      "Number of nodes: 29\n",
      "Number of edges: 720\n",
      "Average node degree: 24.83\n",
      "Has isolated nodes: False\n",
      "Has self-loops: True\n",
      "Is undirected: True\n",
      "\n",
      "Data(x=[29, 64], edge_index=[2, 741], edge_attr=[741], y=[29])\n",
      "===========================================================================================================\n",
      "Number of nodes: 29\n",
      "Number of edges: 741\n",
      "Average node degree: 25.55\n",
      "Has isolated nodes: False\n",
      "Has self-loops: True\n",
      "Is undirected: True\n"
     ]
    }
   ],
   "source": [
    "for path in paths:\n",
    "    dataset = torch.load(path)\n",
    "    data = dataset[0]\n",
    "    data_list.append(transform_and_split(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([29, 62])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list[1].x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "edge_indices = [i.edge_index.double() for i in data_list]\n",
    "edge_weights = [i.edge_attr.double() for i in data_list]\n",
    "features = [i.x.double() for i in data_list]\n",
    "targets = [i.y.double() for i in data_list]\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "edge_indices = [i.edge_index.cpu().detach().numpy() for i in data_list]\n",
    "edge_weights = [i.edge_attr.cpu().detach().numpy() for i in data_list]\n",
    "features = [i.x.cpu().detach().numpy() for i in data_list]\n",
    "targets = [i.y.cpu().detach().numpy() for i in data_list]\n",
    "\"\"\"\n",
    "edge_indices = [i.edge_index.numpy() for i in data_list]\n",
    "edge_weights = [i.edge_attr.numpy() for i in data_list]\n",
    "features = [i.x.numpy() for i in data_list]\n",
    "targets = [i.y.numpy() for i in data_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29, 62)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_features = []\n",
    "for i in features:\n",
    "    padded_features.append(np.pad(i, [(0, 0), (0, 64-i.shape[1])], 'mean'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric_temporal.signal import DynamicGraphTemporalSignal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal_signal = DynamicGraphTemporalSignal(edge_indices = edge_indices , edge_weights = edge_weights, features = padded_features, targets = targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch_geometric_temporal.signal.dynamic_graph_temporal_signal.DynamicGraphTemporalSignal at 0x26f36af77f0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temporal_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric_temporal.signal import temporal_signal_split\n",
    "\n",
    "train_dataset, test_dataset = temporal_signal_split(temporal_signal, train_ratio=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric_temporal.nn.recurrent import DCRNN\n",
    "from torch_geometric_temporal import TemporalConv\n",
    "from torch_geometric_temporal import EvolveGCNO\n",
    "class RecurrentGCN(torch.nn.Module):\n",
    "    def __init__(self, node_features):\n",
    "        super(RecurrentGCN, self).__init__()\n",
    "        self.evol = EvolveGCNO(node_features)\n",
    "        self.recurrent = DCRNN(node_features, 32, 1)\n",
    "        self.linear = torch.nn.Linear(64, 1)\n",
    "        self.dropout = torch.nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight):\n",
    "        h = self.evol(x, edge_index, edge_weight)\n",
    "#        h = self.dropout(h)\n",
    "#        h = self.recurrent(x, edge_index, edge_weight)\n",
    "        h = F.relu(h)\n",
    "        h = self.linear(h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Data(x=[29, 64], edge_index=[2, 760], edge_attr=[760], y=[29])\n",
      "1\n",
      "Data(x=[29, 64], edge_index=[2, 312], edge_attr=[312], y=[29])\n",
      "2\n",
      "Data(x=[29, 64], edge_index=[2, 400], edge_attr=[400], y=[29])\n",
      "3\n",
      "Data(x=[29, 64], edge_index=[2, 552], edge_attr=[552], y=[29])\n",
      "4\n",
      "Data(x=[29, 64], edge_index=[2, 805], edge_attr=[805], y=[29])\n",
      "5\n",
      "Data(x=[29, 64], edge_index=[2, 400], edge_attr=[400], y=[29])\n",
      "6\n",
      "Data(x=[29, 64], edge_index=[2, 616], edge_attr=[616], y=[29])\n",
      "7\n",
      "Data(x=[29, 64], edge_index=[2, 585], edge_attr=[585], y=[29])\n",
      "8\n",
      "Data(x=[29, 64], edge_index=[2, 805], edge_attr=[805], y=[29])\n",
      "9\n",
      "Data(x=[29, 64], edge_index=[2, 552], edge_attr=[552], y=[29])\n",
      "10\n",
      "Data(x=[29, 64], edge_index=[2, 552], edge_attr=[552], y=[29])\n",
      "11\n",
      "Data(x=[29, 64], edge_index=[2, 672], edge_attr=[672], y=[29])\n",
      "12\n",
      "Data(x=[29, 64], edge_index=[2, 777], edge_attr=[777], y=[29])\n",
      "13\n",
      "Data(x=[29, 64], edge_index=[2, 480], edge_attr=[480], y=[29])\n",
      "14\n",
      "Data(x=[29, 64], edge_index=[2, 585], edge_attr=[585], y=[29])\n",
      "15\n",
      "Data(x=[29, 64], edge_index=[2, 697], edge_attr=[697], y=[29])\n",
      "16\n",
      "Data(x=[29, 64], edge_index=[2, 805], edge_attr=[805], y=[29])\n",
      "17\n",
      "Data(x=[29, 64], edge_index=[2, 616], edge_attr=[616], y=[29])\n",
      "18\n",
      "Data(x=[29, 64], edge_index=[2, 720], edge_attr=[720], y=[29])\n",
      "19\n",
      "Data(x=[29, 64], edge_index=[2, 741], edge_attr=[741], y=[29])\n"
     ]
    }
   ],
   "source": [
    "for time, snapshot in enumerate(temporal_signal):\n",
    "    print(time)\n",
    "    print(snapshot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:09<00:00, 21.95it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "model = RecurrentGCN(node_features = 64)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "model.train()\n",
    "\n",
    "for epoch in tqdm(range(200)):\n",
    "    cost = 0\n",
    "    for time, snapshot in enumerate(train_dataset):\n",
    "        y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n",
    "        cost = cost + torch.mean((y_hat-snapshot.y)**2)\n",
    "    cost = cost / (time+1)\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.2267\n"
     ]
    }
   ],
   "source": [
    "y_hat_l = []\n",
    "model.eval()\n",
    "cost = 0\n",
    "for time, snapshot in enumerate(test_dataset):\n",
    "    y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n",
    "    cost = cost + torch.mean((y_hat-snapshot.y)**2)\n",
    "    y_hat_l.append(y_hat)\n",
    "cost = cost / (time+1)\n",
    "cost = cost.item()\n",
    "print(\"MSE: {:.4f}\".format(cost))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[0.6851],\n",
       "         [0.6821],\n",
       "         [0.6825],\n",
       "         [0.7087],\n",
       "         [0.6917],\n",
       "         [0.6841],\n",
       "         [0.6822],\n",
       "         [0.6838],\n",
       "         [0.6896],\n",
       "         [0.6963],\n",
       "         [0.6868],\n",
       "         [0.6874],\n",
       "         [0.6823],\n",
       "         [0.6826],\n",
       "         [0.6821],\n",
       "         [0.6823],\n",
       "         [0.6973],\n",
       "         [0.6842],\n",
       "         [0.7016],\n",
       "         [0.6821],\n",
       "         [0.6858],\n",
       "         [0.6837],\n",
       "         [0.6856],\n",
       "         [0.6821],\n",
       "         [0.6826],\n",
       "         [0.7724],\n",
       "         [0.6830],\n",
       "         [0.6821],\n",
       "         [0.6830]], grad_fn=<AddmmBackward>),\n",
       " tensor([[0.6738],\n",
       "         [0.6740],\n",
       "         [0.6742],\n",
       "         [0.6851],\n",
       "         [0.6843],\n",
       "         [0.6739],\n",
       "         [0.6741],\n",
       "         [0.6747],\n",
       "         [0.6807],\n",
       "         [0.6856],\n",
       "         [0.6758],\n",
       "         [0.6756],\n",
       "         [0.6741],\n",
       "         [0.6741],\n",
       "         [0.6740],\n",
       "         [0.6742],\n",
       "         [0.6781],\n",
       "         [0.6741],\n",
       "         [0.6749],\n",
       "         [0.6740],\n",
       "         [0.6740],\n",
       "         [0.6809],\n",
       "         [0.6789],\n",
       "         [0.6741],\n",
       "         [0.6741],\n",
       "         [0.7333],\n",
       "         [0.6749],\n",
       "         [0.6741],\n",
       "         [0.6787]], grad_fn=<AddmmBackward>),\n",
       " tensor([[0.6635],\n",
       "         [0.6650],\n",
       "         [0.6646],\n",
       "         [0.6558],\n",
       "         [0.6582],\n",
       "         [0.6622],\n",
       "         [0.6651],\n",
       "         [0.6651],\n",
       "         [0.6627],\n",
       "         [0.6606],\n",
       "         [0.6644],\n",
       "         [0.6647],\n",
       "         [0.6646],\n",
       "         [0.6650],\n",
       "         [0.6650],\n",
       "         [0.6647],\n",
       "         [0.6633],\n",
       "         [0.6647],\n",
       "         [0.6650],\n",
       "         [0.6651],\n",
       "         [0.6646],\n",
       "         [0.6598],\n",
       "         [0.6647],\n",
       "         [0.6650],\n",
       "         [0.6650],\n",
       "         [0.6438],\n",
       "         [0.6650],\n",
       "         [0.6650],\n",
       "         [0.6642]], grad_fn=<AddmmBackward>),\n",
       " tensor([[0.6528],\n",
       "         [0.6528],\n",
       "         [0.6528],\n",
       "         [0.6440],\n",
       "         [0.6490],\n",
       "         [0.6512],\n",
       "         [0.6529],\n",
       "         [0.6522],\n",
       "         [0.6502],\n",
       "         [0.6476],\n",
       "         [0.6519],\n",
       "         [0.6498],\n",
       "         [0.6528],\n",
       "         [0.6528],\n",
       "         [0.6528],\n",
       "         [0.6529],\n",
       "         [0.6492],\n",
       "         [0.6520],\n",
       "         [0.6482],\n",
       "         [0.6528],\n",
       "         [0.6523],\n",
       "         [0.6517],\n",
       "         [0.6524],\n",
       "         [0.6528],\n",
       "         [0.6528],\n",
       "         [0.6184],\n",
       "         [0.6527],\n",
       "         [0.6529],\n",
       "         [0.6526]], grad_fn=<AddmmBackward>)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_l = [list(np.squeeze(i.detach().numpy())) for i in y_hat_l]\n",
    "y_hat_l = [z for y in y_hat_l for z in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_list = [1 if x > 0.66 else 0 for x in y_hat_l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_label = []\n",
    "for time, snapshot in enumerate(test_dataset):\n",
    "    true_label.append(list(snapshot.y.detach().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_label = [int(z) for y in true_label for z in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.67      0.52      0.59        42\n",
      "     class 1       0.76      0.85      0.80        74\n",
      "\n",
      "    accuracy                           0.73       116\n",
      "   macro avg       0.71      0.69      0.69       116\n",
      "weighted avg       0.73      0.73      0.72       116\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "y_true = true_label\n",
    "target_names = ['class 0', 'class 1']\n",
    "print(classification_report(y_true, y_hat_list, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
