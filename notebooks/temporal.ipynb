{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 706,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def transform_and_split(data):\n",
    "    # Normalize node features and transform data type\n",
    "    data.x = normalize(data.x, axis=1, norm='max')\n",
    "    data.x = torch.from_numpy(data.x).to(torch.float64)\n",
    "    data.y = data.y.apply_(lambda x:  1 if (x > 0) else 0) # Change y into {0, 1} for binary classification\n",
    "    data.y = data.y.to(torch.float64)    \n",
    "    data.edge_attr = data.edge_attr.to(torch.double)\n",
    "\n",
    "\n",
    "    # Split into train/test set\n",
    "    split = nodeSplit(split=\"train_rest\", num_splits = 1, num_val = 0.0, num_test= 0.2)\n",
    "    masked_data = split(data)\n",
    "\n",
    "    print(\"Training samples:\", torch.sum(masked_data.train_mask).item())\n",
    "    print(\"Validation samples:\", torch.sum(masked_data.val_mask ).item())\n",
    "    print(\"Test samples:\", torch.sum(masked_data.test_mask ).item())\n",
    "    print_basic_info(masked_data)\n",
    "    return masked_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_basic_info(data):\n",
    "    print()\n",
    "    print(data)\n",
    "    print('===========================================================================================================')\n",
    "\n",
    "    print(f'Number of nodes: {data.num_nodes}')\n",
    "    print(f'Number of edges: {data.num_edges}')\n",
    "    print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
    "    print(f'Has isolated nodes: {data.has_isolated_nodes()}')\n",
    "    print(f'Has self-loops: {data.has_self_loops()}')\n",
    "    print(f'Is undirected: {data.is_undirected()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get and split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 23\n",
      "Validation samples: 0\n",
      "Test samples: 6\n",
      "\n",
      "Data(x=[29, 61], edge_index=[2, 400], edge_attr=[400], y=[29], train_mask=[29], val_mask=[29], test_mask=[29])\n",
      "===========================================================================================================\n",
      "Number of nodes: 29\n",
      "Number of edges: 400\n",
      "Average node degree: 13.79\n",
      "Has isolated nodes: False\n",
      "Has self-loops: True\n",
      "Is undirected: True\n"
     ]
    }
   ],
   "source": [
    "path = \"../../data/processed/twitter/2018_q1.pt\" # Customize...\n",
    "dataset = torch.load(path)\n",
    "data = dataset[0]\n",
    "transformed_data = transform_and_split(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric_temporal.dataset import ChickenpoxDatasetLoader\n",
    "\n",
    "loader = ChickenpoxDatasetLoader()\n",
    "\n",
    "dataset = loader.get_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 710,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.edge_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../../data/processed/twitter/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "metadata": {},
   "outputs": [],
   "source": [
    "quarter = ['2016_q4']\n",
    "for i in range(2017, 2022):\n",
    "    for j in range(1, 5):\n",
    "        if i == 2021 and j == 4: break\n",
    "        quarter.append(str(i)+'_q'+str(j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2016_q4',\n",
       " '2017_q1',\n",
       " '2017_q2',\n",
       " '2017_q3',\n",
       " '2017_q4',\n",
       " '2018_q1',\n",
       " '2018_q2',\n",
       " '2018_q3',\n",
       " '2018_q4',\n",
       " '2019_q1',\n",
       " '2019_q2',\n",
       " '2019_q3',\n",
       " '2019_q4',\n",
       " '2020_q1',\n",
       " '2020_q2',\n",
       " '2020_q3',\n",
       " '2020_q4',\n",
       " '2021_q1',\n",
       " '2021_q2',\n",
       " '2021_q3']"
      ]
     },
     "execution_count": 713,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quarter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = []\n",
    "for i in quarter:\n",
    "    paths.append(path+i+'.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../data/processed/twitter/2016_q4.pt',\n",
       " '../../data/processed/twitter/2017_q1.pt',\n",
       " '../../data/processed/twitter/2017_q2.pt',\n",
       " '../../data/processed/twitter/2017_q3.pt',\n",
       " '../../data/processed/twitter/2017_q4.pt',\n",
       " '../../data/processed/twitter/2018_q1.pt',\n",
       " '../../data/processed/twitter/2018_q2.pt',\n",
       " '../../data/processed/twitter/2018_q3.pt',\n",
       " '../../data/processed/twitter/2018_q4.pt',\n",
       " '../../data/processed/twitter/2019_q1.pt',\n",
       " '../../data/processed/twitter/2019_q2.pt',\n",
       " '../../data/processed/twitter/2019_q3.pt',\n",
       " '../../data/processed/twitter/2019_q4.pt',\n",
       " '../../data/processed/twitter/2020_q1.pt',\n",
       " '../../data/processed/twitter/2020_q2.pt',\n",
       " '../../data/processed/twitter/2020_q3.pt',\n",
       " '../../data/processed/twitter/2020_q4.pt',\n",
       " '../../data/processed/twitter/2021_q1.pt',\n",
       " '../../data/processed/twitter/2021_q2.pt',\n",
       " '../../data/processed/twitter/2021_q3.pt']"
      ]
     },
     "execution_count": 715,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 23\n",
      "Validation samples: 0\n",
      "Test samples: 6\n",
      "\n",
      "Data(x=[29, 63], edge_index=[2, 760], edge_attr=[760], y=[29], train_mask=[29], val_mask=[29], test_mask=[29])\n",
      "===========================================================================================================\n",
      "Number of nodes: 29\n",
      "Number of edges: 760\n",
      "Average node degree: 26.21\n",
      "Has isolated nodes: False\n",
      "Has self-loops: True\n",
      "Is undirected: True\n",
      "Training samples: 23\n",
      "Validation samples: 0\n",
      "Test samples: 6\n",
      "\n",
      "Data(x=[29, 62], edge_index=[2, 312], edge_attr=[312], y=[29], train_mask=[29], val_mask=[29], test_mask=[29])\n",
      "===========================================================================================================\n",
      "Number of nodes: 29\n",
      "Number of edges: 312\n",
      "Average node degree: 10.76\n",
      "Has isolated nodes: False\n",
      "Has self-loops: True\n",
      "Is undirected: True\n",
      "Training samples: 23\n",
      "Validation samples: 0\n",
      "Test samples: 6\n",
      "\n",
      "Data(x=[29, 63], edge_index=[2, 400], edge_attr=[400], y=[29], train_mask=[29], val_mask=[29], test_mask=[29])\n",
      "===========================================================================================================\n",
      "Number of nodes: 29\n",
      "Number of edges: 400\n",
      "Average node degree: 13.79\n",
      "Has isolated nodes: False\n",
      "Has self-loops: True\n",
      "Is undirected: True\n",
      "Training samples: 23\n",
      "Validation samples: 0\n",
      "Test samples: 6\n",
      "\n",
      "Data(x=[29, 63], edge_index=[2, 552], edge_attr=[552], y=[29], train_mask=[29], val_mask=[29], test_mask=[29])\n",
      "===========================================================================================================\n",
      "Number of nodes: 29\n",
      "Number of edges: 552\n",
      "Average node degree: 19.03\n",
      "Has isolated nodes: False\n",
      "Has self-loops: True\n",
      "Is undirected: True\n",
      "Training samples: 23\n",
      "Validation samples: 0\n",
      "Test samples: 6\n",
      "\n",
      "Data(x=[29, 63], edge_index=[2, 805], edge_attr=[805], y=[29], train_mask=[29], val_mask=[29], test_mask=[29])\n",
      "===========================================================================================================\n",
      "Number of nodes: 29\n",
      "Number of edges: 805\n",
      "Average node degree: 27.76\n",
      "Has isolated nodes: False\n",
      "Has self-loops: True\n",
      "Is undirected: True\n",
      "Training samples: 23\n",
      "Validation samples: 0\n",
      "Test samples: 6\n",
      "\n",
      "Data(x=[29, 61], edge_index=[2, 400], edge_attr=[400], y=[29], train_mask=[29], val_mask=[29], test_mask=[29])\n",
      "===========================================================================================================\n",
      "Number of nodes: 29\n",
      "Number of edges: 400\n",
      "Average node degree: 13.79\n",
      "Has isolated nodes: False\n",
      "Has self-loops: True\n",
      "Is undirected: True\n",
      "Training samples: 23\n",
      "Validation samples: 0\n",
      "Test samples: 6\n",
      "\n",
      "Data(x=[29, 64], edge_index=[2, 616], edge_attr=[616], y=[29], train_mask=[29], val_mask=[29], test_mask=[29])\n",
      "===========================================================================================================\n",
      "Number of nodes: 29\n",
      "Number of edges: 616\n",
      "Average node degree: 21.24\n",
      "Has isolated nodes: False\n",
      "Has self-loops: True\n",
      "Is undirected: True\n",
      "Training samples: 23\n",
      "Validation samples: 0\n",
      "Test samples: 6\n",
      "\n",
      "Data(x=[29, 63], edge_index=[2, 585], edge_attr=[585], y=[29], train_mask=[29], val_mask=[29], test_mask=[29])\n",
      "===========================================================================================================\n",
      "Number of nodes: 29\n",
      "Number of edges: 585\n",
      "Average node degree: 20.17\n",
      "Has isolated nodes: False\n",
      "Has self-loops: True\n",
      "Is undirected: True\n",
      "Training samples: 23\n",
      "Validation samples: 0\n",
      "Test samples: 6\n",
      "\n",
      "Data(x=[29, 63], edge_index=[2, 805], edge_attr=[805], y=[29], train_mask=[29], val_mask=[29], test_mask=[29])\n",
      "===========================================================================================================\n",
      "Number of nodes: 29\n",
      "Number of edges: 805\n",
      "Average node degree: 27.76\n",
      "Has isolated nodes: False\n",
      "Has self-loops: True\n",
      "Is undirected: True\n",
      "Training samples: 23\n",
      "Validation samples: 0\n",
      "Test samples: 6\n",
      "\n",
      "Data(x=[29, 61], edge_index=[2, 552], edge_attr=[552], y=[29], train_mask=[29], val_mask=[29], test_mask=[29])\n",
      "===========================================================================================================\n",
      "Number of nodes: 29\n",
      "Number of edges: 552\n",
      "Average node degree: 19.03\n",
      "Has isolated nodes: False\n",
      "Has self-loops: True\n",
      "Is undirected: True\n",
      "Training samples: 23\n",
      "Validation samples: 0\n",
      "Test samples: 6\n",
      "\n",
      "Data(x=[29, 63], edge_index=[2, 552], edge_attr=[552], y=[29], train_mask=[29], val_mask=[29], test_mask=[29])\n",
      "===========================================================================================================\n",
      "Number of nodes: 29\n",
      "Number of edges: 552\n",
      "Average node degree: 19.03\n",
      "Has isolated nodes: False\n",
      "Has self-loops: True\n",
      "Is undirected: True\n",
      "Training samples: 23\n",
      "Validation samples: 0\n",
      "Test samples: 6\n",
      "\n",
      "Data(x=[29, 64], edge_index=[2, 672], edge_attr=[672], y=[29], train_mask=[29], val_mask=[29], test_mask=[29])\n",
      "===========================================================================================================\n",
      "Number of nodes: 29\n",
      "Number of edges: 672\n",
      "Average node degree: 23.17\n",
      "Has isolated nodes: False\n",
      "Has self-loops: True\n",
      "Is undirected: True\n",
      "Training samples: 23\n",
      "Validation samples: 0\n",
      "Test samples: 6\n",
      "\n",
      "Data(x=[29, 64], edge_index=[2, 777], edge_attr=[777], y=[29], train_mask=[29], val_mask=[29], test_mask=[29])\n",
      "===========================================================================================================\n",
      "Number of nodes: 29\n",
      "Number of edges: 777\n",
      "Average node degree: 26.79\n",
      "Has isolated nodes: False\n",
      "Has self-loops: True\n",
      "Is undirected: True\n",
      "Training samples: 23\n",
      "Validation samples: 0\n",
      "Test samples: 6\n",
      "\n",
      "Data(x=[29, 62], edge_index=[2, 480], edge_attr=[480], y=[29], train_mask=[29], val_mask=[29], test_mask=[29])\n",
      "===========================================================================================================\n",
      "Number of nodes: 29\n",
      "Number of edges: 480\n",
      "Average node degree: 16.55\n",
      "Has isolated nodes: False\n",
      "Has self-loops: True\n",
      "Is undirected: True\n",
      "Training samples: 23\n",
      "Validation samples: 0\n",
      "Test samples: 6\n",
      "\n",
      "Data(x=[29, 63], edge_index=[2, 585], edge_attr=[585], y=[29], train_mask=[29], val_mask=[29], test_mask=[29])\n",
      "===========================================================================================================\n",
      "Number of nodes: 29\n",
      "Number of edges: 585\n",
      "Average node degree: 20.17\n",
      "Has isolated nodes: False\n",
      "Has self-loops: True\n",
      "Is undirected: True\n",
      "Training samples: 23\n",
      "Validation samples: 0\n",
      "Test samples: 6\n",
      "\n",
      "Data(x=[29, 64], edge_index=[2, 697], edge_attr=[697], y=[29], train_mask=[29], val_mask=[29], test_mask=[29])\n",
      "===========================================================================================================\n",
      "Number of nodes: 29\n",
      "Number of edges: 697\n",
      "Average node degree: 24.03\n",
      "Has isolated nodes: False\n",
      "Has self-loops: True\n",
      "Is undirected: True\n",
      "Training samples: 23\n",
      "Validation samples: 0\n",
      "Test samples: 6\n",
      "\n",
      "Data(x=[29, 64], edge_index=[2, 805], edge_attr=[805], y=[29], train_mask=[29], val_mask=[29], test_mask=[29])\n",
      "===========================================================================================================\n",
      "Number of nodes: 29\n",
      "Number of edges: 805\n",
      "Average node degree: 27.76\n",
      "Has isolated nodes: False\n",
      "Has self-loops: True\n",
      "Is undirected: True\n",
      "Training samples: 23\n",
      "Validation samples: 0\n",
      "Test samples: 6\n",
      "\n",
      "Data(x=[29, 61], edge_index=[2, 616], edge_attr=[616], y=[29], train_mask=[29], val_mask=[29], test_mask=[29])\n",
      "===========================================================================================================\n",
      "Number of nodes: 29\n",
      "Number of edges: 616\n",
      "Average node degree: 21.24\n",
      "Has isolated nodes: False\n",
      "Has self-loops: True\n",
      "Is undirected: True\n",
      "Training samples: 23\n",
      "Validation samples: 0\n",
      "Test samples: 6\n",
      "\n",
      "Data(x=[29, 63], edge_index=[2, 720], edge_attr=[720], y=[29], train_mask=[29], val_mask=[29], test_mask=[29])\n",
      "===========================================================================================================\n",
      "Number of nodes: 29\n",
      "Number of edges: 720\n",
      "Average node degree: 24.83\n",
      "Has isolated nodes: False\n",
      "Has self-loops: True\n",
      "Is undirected: True\n",
      "Training samples: 23\n",
      "Validation samples: 0\n",
      "Test samples: 6\n",
      "\n",
      "Data(x=[29, 64], edge_index=[2, 741], edge_attr=[741], y=[29], train_mask=[29], val_mask=[29], test_mask=[29])\n",
      "===========================================================================================================\n",
      "Number of nodes: 29\n",
      "Number of edges: 741\n",
      "Average node degree: 25.55\n",
      "Has isolated nodes: False\n",
      "Has self-loops: True\n",
      "Is undirected: True\n"
     ]
    }
   ],
   "source": [
    "for path in paths:\n",
    "    dataset = torch.load(path)\n",
    "    data = dataset[0]\n",
    "    data_list.append(transform_and_split(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 718,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([29, 62])"
      ]
     },
     "execution_count": 719,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list[1].x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "edge_indices = [i.edge_index.double() for i in data_list]\n",
    "edge_weights = [i.edge_attr.double() for i in data_list]\n",
    "features = [i.x.double() for i in data_list]\n",
    "targets = [i.y.double() for i in data_list]\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "edge_indices = [i.edge_index.cpu().detach().numpy() for i in data_list]\n",
    "edge_weights = [i.edge_attr.cpu().detach().numpy() for i in data_list]\n",
    "features = [i.x.cpu().detach().numpy() for i in data_list]\n",
    "targets = [i.y.cpu().detach().numpy() for i in data_list]\n",
    "\"\"\"\n",
    "edge_indices = [i.edge_index.numpy() for i in data_list]\n",
    "edge_weights = [i.edge_attr.numpy() for i in data_list]\n",
    "features = [i.x.numpy() for i in data_list]\n",
    "targets = [i.y.numpy() for i in data_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29, 62)"
      ]
     },
     "execution_count": 721,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_features = []\n",
    "for i in features:\n",
    "    padded_features.append(np.pad(i, [(0, 0), (0, 70-i.shape[1])], 'mean'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric_temporal.signal import DynamicGraphTemporalSignal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal_signal = DynamicGraphTemporalSignal(edge_indices = edge_indices , edge_weights = edge_weights, features = padded_features, targets = targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 725,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch_geometric_temporal.signal.dynamic_graph_temporal_signal.DynamicGraphTemporalSignal at 0x29438ec2040>"
      ]
     },
     "execution_count": 725,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temporal_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 726,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric_temporal.signal import temporal_signal_split\n",
    "\n",
    "train_dataset, test_dataset = temporal_signal_split(temporal_signal, train_ratio=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 727,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric_temporal.nn.recurrent import DCRNN\n",
    "from torch_geometric_temporal import TemporalConv\n",
    "from torch_geometric_temporal import EvolveGCNO\n",
    "class RecurrentGCN(torch.nn.Module):\n",
    "    def __init__(self, node_features):\n",
    "        super(RecurrentGCN, self).__init__()\n",
    "        self.evol = EvolveGCNO(node_features)\n",
    " #       self.recurrent = DCRNN(node_features, 32, 1)\n",
    "        self.linear = torch.nn.Linear(70, 1)\n",
    " #       self.conv = TemporalConv(32, 16, 3)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight):\n",
    "        h = self.evol(x, edge_index, edge_weight)\n",
    " #       h = self.conv(h)\n",
    "\n",
    "        h = F.relu(h)\n",
    "        h = self.linear(h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Data(x=[29, 70], edge_index=[2, 760], edge_attr=[760], y=[29])\n",
      "1\n",
      "Data(x=[29, 70], edge_index=[2, 312], edge_attr=[312], y=[29])\n",
      "2\n",
      "Data(x=[29, 70], edge_index=[2, 400], edge_attr=[400], y=[29])\n",
      "3\n",
      "Data(x=[29, 70], edge_index=[2, 552], edge_attr=[552], y=[29])\n",
      "4\n",
      "Data(x=[29, 70], edge_index=[2, 805], edge_attr=[805], y=[29])\n",
      "5\n",
      "Data(x=[29, 70], edge_index=[2, 400], edge_attr=[400], y=[29])\n",
      "6\n",
      "Data(x=[29, 70], edge_index=[2, 616], edge_attr=[616], y=[29])\n",
      "7\n",
      "Data(x=[29, 70], edge_index=[2, 585], edge_attr=[585], y=[29])\n",
      "8\n",
      "Data(x=[29, 70], edge_index=[2, 805], edge_attr=[805], y=[29])\n",
      "9\n",
      "Data(x=[29, 70], edge_index=[2, 552], edge_attr=[552], y=[29])\n",
      "10\n",
      "Data(x=[29, 70], edge_index=[2, 552], edge_attr=[552], y=[29])\n",
      "11\n",
      "Data(x=[29, 70], edge_index=[2, 672], edge_attr=[672], y=[29])\n",
      "12\n",
      "Data(x=[29, 70], edge_index=[2, 777], edge_attr=[777], y=[29])\n",
      "13\n",
      "Data(x=[29, 70], edge_index=[2, 480], edge_attr=[480], y=[29])\n",
      "14\n",
      "Data(x=[29, 70], edge_index=[2, 585], edge_attr=[585], y=[29])\n",
      "15\n",
      "Data(x=[29, 70], edge_index=[2, 697], edge_attr=[697], y=[29])\n",
      "16\n",
      "Data(x=[29, 70], edge_index=[2, 805], edge_attr=[805], y=[29])\n",
      "17\n",
      "Data(x=[29, 70], edge_index=[2, 616], edge_attr=[616], y=[29])\n",
      "18\n",
      "Data(x=[29, 70], edge_index=[2, 720], edge_attr=[720], y=[29])\n",
      "19\n",
      "Data(x=[29, 70], edge_index=[2, 741], edge_attr=[741], y=[29])\n"
     ]
    }
   ],
   "source": [
    "for time, snapshot in enumerate(temporal_signal):\n",
    "    print(time)\n",
    "    print(snapshot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 748,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:04<00:00, 43.08it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "model = RecurrentGCN(node_features = 70)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "model.train()\n",
    "\n",
    "for epoch in tqdm(range(200)):\n",
    "    cost = 0\n",
    "    for time, snapshot in enumerate(train_dataset):\n",
    "        y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n",
    "        cost = cost + torch.mean((y_hat-snapshot.y)**2)\n",
    "    cost = cost / (time+1)\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 749,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.2269\n"
     ]
    }
   ],
   "source": [
    "y_hat_l = []\n",
    "model.eval()\n",
    "cost = 0\n",
    "for time, snapshot in enumerate(test_dataset):\n",
    "    y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n",
    "    cost = cost + torch.mean((y_hat-snapshot.y)**2)\n",
    "    y_hat_l.append(y_hat)\n",
    "cost = cost / (time+1)\n",
    "cost = cost.item()\n",
    "print(\"MSE: {:.4f}\".format(cost))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 750,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[0.6778],\n",
       "         [0.6744],\n",
       "         [0.6749],\n",
       "         [0.7046],\n",
       "         [0.6850],\n",
       "         [0.6767],\n",
       "         [0.6745],\n",
       "         [0.6763],\n",
       "         [0.6830],\n",
       "         [0.6907],\n",
       "         [0.6798],\n",
       "         [0.6803],\n",
       "         [0.6747],\n",
       "         [0.6750],\n",
       "         [0.6745],\n",
       "         [0.6747],\n",
       "         [0.6916],\n",
       "         [0.6768],\n",
       "         [0.6965],\n",
       "         [0.6744],\n",
       "         [0.6787],\n",
       "         [0.6763],\n",
       "         [0.6784],\n",
       "         [0.6745],\n",
       "         [0.6749],\n",
       "         [0.7770],\n",
       "         [0.6754],\n",
       "         [0.6745],\n",
       "         [0.6755]], grad_fn=<AddmmBackward>),\n",
       " tensor([[0.6650],\n",
       "         [0.6651],\n",
       "         [0.6654],\n",
       "         [0.6796],\n",
       "         [0.6785],\n",
       "         [0.6650],\n",
       "         [0.6653],\n",
       "         [0.6660],\n",
       "         [0.6737],\n",
       "         [0.6799],\n",
       "         [0.6674],\n",
       "         [0.6673],\n",
       "         [0.6652],\n",
       "         [0.6653],\n",
       "         [0.6651],\n",
       "         [0.6653],\n",
       "         [0.6706],\n",
       "         [0.6652],\n",
       "         [0.6662],\n",
       "         [0.6650],\n",
       "         [0.6652],\n",
       "         [0.6742],\n",
       "         [0.6718],\n",
       "         [0.6653],\n",
       "         [0.6652],\n",
       "         [0.7401],\n",
       "         [0.6663],\n",
       "         [0.6654],\n",
       "         [0.6712]], grad_fn=<AddmmBackward>),\n",
       " tensor([[0.6575],\n",
       "         [0.6580],\n",
       "         [0.6579],\n",
       "         [0.6568],\n",
       "         [0.6575],\n",
       "         [0.6569],\n",
       "         [0.6581],\n",
       "         [0.6581],\n",
       "         [0.6579],\n",
       "         [0.6564],\n",
       "         [0.6580],\n",
       "         [0.6580],\n",
       "         [0.6579],\n",
       "         [0.6579],\n",
       "         [0.6581],\n",
       "         [0.6580],\n",
       "         [0.6576],\n",
       "         [0.6580],\n",
       "         [0.6581],\n",
       "         [0.6581],\n",
       "         [0.6579],\n",
       "         [0.6575],\n",
       "         [0.6580],\n",
       "         [0.6581],\n",
       "         [0.6581],\n",
       "         [0.6558],\n",
       "         [0.6580],\n",
       "         [0.6580],\n",
       "         [0.6577]], grad_fn=<AddmmBackward>),\n",
       " tensor([[0.6460],\n",
       "         [0.6459],\n",
       "         [0.6459],\n",
       "         [0.6468],\n",
       "         [0.6467],\n",
       "         [0.6459],\n",
       "         [0.6460],\n",
       "         [0.6463],\n",
       "         [0.6459],\n",
       "         [0.6456],\n",
       "         [0.6460],\n",
       "         [0.6465],\n",
       "         [0.6459],\n",
       "         [0.6459],\n",
       "         [0.6459],\n",
       "         [0.6459],\n",
       "         [0.6463],\n",
       "         [0.6460],\n",
       "         [0.6470],\n",
       "         [0.6459],\n",
       "         [0.6459],\n",
       "         [0.6466],\n",
       "         [0.6459],\n",
       "         [0.6459],\n",
       "         [0.6459],\n",
       "         [0.6401],\n",
       "         [0.6460],\n",
       "         [0.6460],\n",
       "         [0.6460]], grad_fn=<AddmmBackward>)]"
      ]
     },
     "execution_count": 750,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 751,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_l = [list(np.squeeze(i.detach().numpy())) for i in y_hat_l]\n",
    "y_hat_l = [z for y in y_hat_l for z in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 768,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_list = [1 if x > 0.65 else 0 for x in y_hat_l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 769,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_label = []\n",
    "for time, snapshot in enumerate(test_dataset):\n",
    "    true_label.append(list(snapshot.y.detach().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 770,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_label = [int(z) for y in true_label for z in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 771,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.69      0.48      0.56        42\n",
      "     class 1       0.75      0.88      0.81        74\n",
      "\n",
      "    accuracy                           0.73       116\n",
      "   macro avg       0.72      0.68      0.69       116\n",
      "weighted avg       0.73      0.73      0.72       116\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "y_true = true_label\n",
    "target_names = ['class 0', 'class 1']\n",
    "print(classification_report(y_true, y_hat_list, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
