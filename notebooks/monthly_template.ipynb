{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "monthly_template.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7e095685",
        "outputId": "6ca8d22d-9de0-49de-d110-1d99c5ea87b4"
      },
      "source": [
        "# Changed...\n",
        "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-1.10.0+cu113.html\n",
        "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-1.10.0+cu113.html\n",
        "!pip install torch-geometric\n",
        "!pip install torch-geometric-temporal\n",
        "\n",
        "import sys\n",
        "sys.path.append(\".\")"
      ],
      "id": "7e095685",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.7/dist-packages (2.0.2)\n",
            "Requirement already satisfied: yacs in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (0.1.8)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.19.5)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (3.13)\n",
            "Requirement already satisfied: googledrivedownloader in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (0.4)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (4.62.3)\n",
            "Requirement already satisfied: rdflib in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (6.0.2)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (3.0.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.1.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.11.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch-geometric) (2.0.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->torch-geometric) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from rdflib->torch-geometric) (57.4.0)\n",
            "Requirement already satisfied: isodate in /usr/local/lib/python3.7/dist-packages (from rdflib->torch-geometric) (0.6.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2.10)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (3.0.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (1.1.0)\n",
            "Collecting torch-geometric-temporal\n",
            "  Downloading torch_geometric_temporal-0.41.tar.gz (42 kB)\n",
            "\u001b[K     |████████████████████████████████| 42 kB 577 kB/s \n",
            "\u001b[?25hRequirement already satisfied: decorator==4.4.2 in /usr/local/lib/python3.7/dist-packages (from torch-geometric-temporal) (4.4.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torch-geometric-temporal) (1.10.0+cu111)\n",
            "Requirement already satisfied: torch_sparse in /usr/local/lib/python3.7/dist-packages (from torch-geometric-temporal) (0.6.12)\n",
            "Requirement already satisfied: torch_scatter in /usr/local/lib/python3.7/dist-packages (from torch-geometric-temporal) (2.0.9)\n",
            "Collecting torch_cluster\n",
            "  Downloading torch_cluster-1.5.9.tar.gz (38 kB)\n",
            "Collecting torch_spline_conv\n",
            "  Downloading torch_spline_conv-1.2.1.tar.gz (13 kB)\n",
            "Requirement already satisfied: torch_geometric in /usr/local/lib/python3.7/dist-packages (from torch-geometric-temporal) (2.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-geometric-temporal) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-geometric-temporal) (1.4.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-geometric-temporal) (4.62.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from torch-geometric-temporal) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torch-geometric-temporal) (3.10.0.2)\n",
            "Requirement already satisfied: googledrivedownloader in /usr/local/lib/python3.7/dist-packages (from torch_geometric->torch-geometric-temporal) (0.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch_geometric->torch-geometric-temporal) (1.0.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from torch_geometric->torch-geometric-temporal) (3.13)\n",
            "Requirement already satisfied: yacs in /usr/local/lib/python3.7/dist-packages (from torch_geometric->torch-geometric-temporal) (0.1.8)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from torch_geometric->torch-geometric-temporal) (3.0.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch_geometric->torch-geometric-temporal) (2.11.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from torch_geometric->torch-geometric-temporal) (2.6.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from torch_geometric->torch-geometric-temporal) (1.1.5)\n",
            "Requirement already satisfied: rdflib in /usr/local/lib/python3.7/dist-packages (from torch_geometric->torch-geometric-temporal) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch_geometric->torch-geometric-temporal) (2.23.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch_geometric->torch-geometric-temporal) (2.0.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->torch_geometric->torch-geometric-temporal) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch_geometric->torch-geometric-temporal) (2.8.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from rdflib->torch_geometric->torch-geometric-temporal) (57.4.0)\n",
            "Requirement already satisfied: isodate in /usr/local/lib/python3.7/dist-packages (from rdflib->torch_geometric->torch-geometric-temporal) (0.6.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch_geometric->torch-geometric-temporal) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch_geometric->torch-geometric-temporal) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch_geometric->torch-geometric-temporal) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch_geometric->torch-geometric-temporal) (2021.10.8)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch_geometric->torch-geometric-temporal) (3.0.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch_geometric->torch-geometric-temporal) (1.1.0)\n",
            "Building wheels for collected packages: torch-geometric-temporal, torch-cluster, torch-spline-conv\n",
            "  Building wheel for torch-geometric-temporal (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric-temporal: filename=torch_geometric_temporal-0.41-py3-none-any.whl size=69657 sha256=c0b709736e49ff17a5b138fffcd3f268584fab660db7aa8220195fba496ea13a\n",
            "  Stored in directory: /root/.cache/pip/wheels/d9/96/b2/641bbc9d0b104f4edbfe7b679a516abb3abc7777ea76a77a16\n",
            "  Building wheel for torch-cluster (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-cluster: filename=torch_cluster-1.5.9-cp37-cp37m-linux_x86_64.whl size=317958 sha256=a0e4a96b0239eb1f7df4cbedebb07c6cbb922d378251acf98d312bb284b0a400\n",
            "  Stored in directory: /root/.cache/pip/wheels/a6/60/d8/8bb27f58d8578ba8046f7ea0aadbae89a731db884a644ba361\n",
            "  Building wheel for torch-spline-conv (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-spline-conv: filename=torch_spline_conv-1.2.1-cp37-cp37m-linux_x86_64.whl size=133836 sha256=7f57eec615b46ee0f2cd20b82234aa4c3e23a4ceaab86ebeacddb6f84773765b\n",
            "  Stored in directory: /root/.cache/pip/wheels/9c/33/73/780370b7c7bdf2340c0a7b971e915643f14795b4caa7a9a31f\n",
            "Successfully built torch-geometric-temporal torch-cluster torch-spline-conv\n",
            "Installing collected packages: torch-spline-conv, torch-cluster, torch-geometric-temporal\n",
            "Successfully installed torch-cluster-1.5.9 torch-geometric-temporal-0.41 torch-spline-conv-1.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wn48kWA2SqX"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import argparse\n",
        "\n",
        "import torch\n",
        "from torch_geometric.utils import dense_to_sparse\n",
        "from torch_geometric.data import Data\n",
        "\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "from sklearn import metrics"
      ],
      "id": "8wn48kWA2SqX",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2d91cc0d"
      },
      "source": [
        "# (change this)"
      ],
      "id": "2d91cc0d"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6f659df"
      },
      "source": [
        "# change these variables\n",
        "DATA_ARCHIVE_DIR = \"./data_archive\"\n",
        "news_or_twitter = \"twitter\""
      ],
      "id": "c6f659df",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fe750fa"
      },
      "source": [
        "# convert each .npy file to torch trainable\n",
        "\n",
        "You need basically four things: \n",
        "1. **X** (the nodes' attr: right now is current month avg stock prices). You could modify it at cell 5\n",
        "2. **y** (the next period of time's stock prices: right now is next month avg stock prices). You could modify it at cell 5\n",
        "3. **edge_index** (graph edges: right now is based on co-mentions). You could modify it at cell 6\n",
        "4. **edge_attr** (edges' attr: right now is # of co-mentions during that month). You could modify it at cell 6\n",
        "\n",
        "\n",
        "**dataset** would be a list of Data object that could be directly used for training.\n",
        "\n",
        "modify cell 8&9 to update **model architecture** (right now is simple) and **training process** (e.g. threshold, etc.)\n",
        "\n"
      ],
      "id": "7fe750fa"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d05fb2a6"
      },
      "source": [
        "# sort the files"
      ],
      "id": "d05fb2a6"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f91ed33c"
      },
      "source": [
        "# order the .npy files by time \n",
        "fps = {}\n",
        "for fp in os.listdir(os.path.join(DATA_ARCHIVE_DIR,news_or_twitter)):\n",
        "    if fp.split(\".\")[-1] == \"npy\":\n",
        "        new_name = fp.split(\".\")[0]\n",
        "        if len(new_name.split(\"_\")[1]) == 1:\n",
        "            new_name = new_name.split(\"_\")[0] + \"_\" + \"0\" + new_name.split(\"_\")[1]\n",
        "        fps[fp] = new_name\n",
        "sorted_fps = [k for k, v in sorted(fps.items(), key=lambda item: item[1])]"
      ],
      "id": "f91ed33c",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "366a4b4a"
      },
      "source": [
        "# get stock prices"
      ],
      "id": "366a4b4a"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b14aeb85"
      },
      "source": [
        "# get the stock prices\n",
        "stock_df = pd.read_csv(\n",
        "            os.path.join(DATA_ARCHIVE_DIR,\"stock\",\"raw.csv\"),\n",
        "            usecols=[\"ticker_symbol\", \"Date\", \"Close\"],\n",
        "            parse_dates=[\"Date\"],\n",
        "        )"
      ],
      "id": "b14aeb85",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ce3f45ce"
      },
      "source": [
        "# Prepare X and y (change this)"
      ],
      "id": "ce3f45ce"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00198d75"
      },
      "source": [
        "X_y = []\n",
        "\n",
        "for fp in sorted_fps:\n",
        "    full_fp = os.path.join(DATA_ARCHIVE_DIR,news_or_twitter,fp)\n",
        "    yr_month = fp.split(\".\")[0]\n",
        "    yr = int(yr_month.split(\"_\")[0])\n",
        "    month = int(yr_month.split(\"_\")[1])\n",
        "    # no further data available\n",
        "    if yr == 2021 and month == 10:\n",
        "        continue\n",
        "    \n",
        "    ######################################################## \n",
        "    # prepare X (change this if you want to add SEC emb, etc.)\n",
        "    ########################################################\n",
        "    curr = stock_df[(stock_df.Date.dt.year == yr) & (stock_df.Date.dt.month == month)]\n",
        "    X = curr.pivot_table(\n",
        "            index=\"Date\", columns=\"ticker_symbol\", values=\"Close\"\n",
        "        ).values.T\n",
        "\n",
        "    # ======== Changed: log return normalization ========\n",
        "    x_logret = np.diff(np.log(X))\n",
        "    col_zeros = np.zeros((X.shape[0], 1))\n",
        "    x_normalized = np.append(col_zeros, x_logret, 1)\n",
        "    X_tensor = torch.tensor(x_normalized)\n",
        "    X_tensor = X_tensor.to(torch.float64)\n",
        "    # ===================================================\n",
        "\n",
        "    \n",
        "    ########################################################\n",
        "    # prepare y (change this if you want to change labels)\n",
        "    ########################################################\n",
        "    if month == 12:\n",
        "        y_yr = yr+1\n",
        "        y_month = 1\n",
        "    else:\n",
        "        y_yr = yr\n",
        "        y_month = month + 1\n",
        "    \n",
        "    nxt = stock_df[(stock_df.Date.dt.year == y_yr) & (stock_df.Date.dt.month == y_month)]\n",
        "    y = nxt.pivot_table(\n",
        "            index=\"Date\", columns=\"ticker_symbol\", values=\"Close\"\n",
        "        ).values.T\n",
        "    y = (y.mean(1) - X.mean(1)) / X.mean(1)\n",
        "    y_tensor = torch.tensor(y)\n",
        "\n",
        "    # ======== Changed: biinary label ========\n",
        "    y_tensor = y_tensor.apply_(lambda y:  1 if (y > 0) else 0) # Change y into {0, 1} for binary classification\n",
        "    y_tensor = y_tensor.to(torch.float64)    \n",
        "    # ========================================\n",
        "\n",
        "    X_y.append((X_tensor,y_tensor))\n"
      ],
      "id": "00198d75",
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1065e501"
      },
      "source": [
        "# prepare edges index and attr (change this)"
      ],
      "id": "1065e501"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1b728b5"
      },
      "source": [
        "edges_lst = []\n",
        "for fp in sorted_fps:\n",
        "    full_fp = os.path.join(DATA_ARCHIVE_DIR,news_or_twitter,fp)\n",
        "    yr_month = fp.split(\".\")[0]\n",
        "    yr = int(yr_month.split(\"_\")[0])\n",
        "    month = int(yr_month.split(\"_\")[1])\n",
        "    # no further data available\n",
        "    if yr == 2021 and month == 10: \n",
        "        continue\n",
        "        \n",
        "        \n",
        "    edges = np.load(full_fp)\n",
        "    edge_index, edge_attr = dense_to_sparse(torch.from_numpy(edges))\n",
        "    ######################################################## \n",
        "    # modify edge index and edge attr (change this if you want to change graph structure)\n",
        "    ########################################################\n",
        "    edges_lst.append((edge_index,edge_attr))\n",
        "    "
      ],
      "id": "e1b728b5",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85897c16"
      },
      "source": [
        "## create dataset"
      ],
      "id": "85897c16"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "463fcdd3"
      },
      "source": [
        "dataset = []\n",
        "for i in range(len(X_y)):\n",
        "    X = X_y[i][0]\n",
        "    y = X_y[i][1]\n",
        "    edge_index = edges_lst[i][0]\n",
        "    edge_attr = edges_lst[i][1]\n",
        "    data = Data(x=X, y=y, edge_index=edge_index, edge_attr=edge_attr)\n",
        "    dataset.append(data)"
      ],
      "id": "463fcdd3",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60f8a37a"
      },
      "source": [
        "## model (change this for different NN structure)"
      ],
      "id": "60f8a37a"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f595a7e7"
      },
      "source": [
        "class GNN(torch.nn.Module):\n",
        "    def __init__(self, input_size, feature_size, output_size):\n",
        "        super().__init__()\n",
        "\n",
        "        # Changed: added aother conv layer and a dropout layer\n",
        "        self.conv1 = GCNConv(in_channels=input_size, out_channels=feature_size)\n",
        "        self.activation = nn.ReLU()\n",
        "        self.conv2 = GCNConv(in_channels=feature_size, out_channels=feature_size)\n",
        "        self.fc = nn.Linear(in_features=feature_size, out_features=output_size)\n",
        "        \n",
        "    \n",
        "    def forward(self, data):\n",
        "        node_attr = F.normalize(data.x.float(), dim=0)\n",
        "        num_pad = self.conv1.in_channels - node_attr.shape[1]\n",
        "        node_attr = torch.cat(\n",
        "            (\n",
        "                node_attr,\n",
        "                torch.zeros((node_attr.shape[0], num_pad))\n",
        "            ),\n",
        "            -1\n",
        "        )\n",
        "        edge_index = data.edge_index.long()\n",
        "        edge_weight = F.normalize(data.edge_attr.float().reshape(-1, 1), dim=0)\n",
        "        x = self.conv1(\n",
        "                    x=node_attr, \n",
        "                    edge_index=edge_index, \n",
        "                    edge_weight=edge_weight\n",
        "                    )\n",
        "        x = self.activation(x)\n",
        "        x = F.dropout(x, p=0.2, training=self.training)\n",
        "        x = self.conv2(\n",
        "                    x=node_attr, \n",
        "                    edge_index=data.edge_index, \n",
        "                    edge_weight=data.edge_attr.float()\n",
        "                    )\n",
        "        x = self.fc(x)\n",
        "        return torch.sigmoid(x)\n"
      ],
      "id": "f595a7e7",
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ff52752c"
      },
      "source": [
        "# training starts below"
      ],
      "id": "ff52752c"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83bfc55a"
      },
      "source": [
        "from sklearn import metrics\n",
        "class Trainer:\n",
        "    def __init__(self, model, dataset, args):\n",
        "        self.device = args.device\n",
        "        self.model = model.to(self.device)\n",
        "        self.dataset = dataset\n",
        "        self.epochs = args.num_epochs\n",
        "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr = args.learning_rate)\n",
        "        self.criterion = nn.CrossEntropyLoss().to(self.device)\n",
        "        self.val_idx = int(len(self.dataset) * (1-args.val_size))\n",
        "        self.best_model_weights = self.model.state_dict()\n",
        "        self.best_epoch = 0\n",
        "        self.best_val_loss = float('inf')\n",
        "        self.threshold = args.threshold\n",
        "    def train(self):\n",
        "        for epoch in range(1, self.epochs + 1):\n",
        "            train_loss = 0.0\n",
        "            val_loss = 0.0\n",
        "            for i, data in enumerate(self.dataset):\n",
        "                if i < self.val_idx:\n",
        "                    loss = self._train_step(self.model, data)\n",
        "                    train_loss += loss / self.val_idx\n",
        "                else:\n",
        "                    loss = self._val_step(self.model, data)\n",
        "                    val_loss += loss / (len(self.dataset) - self.val_idx)\n",
        "            # if epoch % 20 == 0 or epoch == self.epochs:\n",
        "            #     print(f\"\"\"\n",
        "            #         epoch {epoch}:\n",
        "            #             train loss: {train_loss},\n",
        "            #             val loss: {val_loss}\n",
        "            #     \"\"\")\n",
        "            if self.best_val_loss > val_loss:\n",
        "                self.best_val_loss = val_loss\n",
        "                self.best_epoch = epoch\n",
        "                self.best_model_weights = model.state_dict()\n",
        "        self.model.load_state_dict(self.best_model_weights)\n",
        "        print(\n",
        "            f\"\"\"\n",
        "            best model loss is:\n",
        "                val loss: {self.best_val_loss} @ epoch: {self.best_epoch}\n",
        "            \"\"\"\n",
        "        )\n",
        "        self._benchmark()\n",
        "        return self.model\n",
        "\n",
        "    def _train_step(self, model, data):\n",
        "        self.optimizer.zero_grad()\n",
        "        logits, target = self._shared_step(model, data)\n",
        "        loss = self.criterion(logits, target)\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "        return loss.item()\n",
        "    def _val_step(self, model, data):\n",
        "        with torch.no_grad():\n",
        "            logits, target = self._shared_step(model, data)\n",
        "            loss = self.criterion(logits, target)\n",
        "            return loss.item()\n",
        "    def _shared_step(self, model, data):\n",
        "        data.x = data.x.to(self.device)\n",
        "        data.edge_index = data.edge_index.to(self.device)\n",
        "        data.edge_attr = data.edge_attr.to(self.device)\n",
        "        target = data.y.long().to(self.device)\n",
        "        logits = model(data)\n",
        "        return logits, target\n",
        "    def _benchmark(self):\n",
        "        train_preds = []\n",
        "        train_trues = []\n",
        "        val_preds = []\n",
        "        val_trues = []\n",
        "        for i, data in enumerate(self.dataset):\n",
        "            logits, target = self._shared_step(self.model, data)\n",
        "            pred = logits.argmax(-1).cpu().numpy()\n",
        "            target = target.cpu().numpy()\n",
        "            if i < self.val_idx:\n",
        "                train_preds.append(pred)\n",
        "                train_trues.append(target)\n",
        "            else:\n",
        "                val_preds.append(pred)\n",
        "                val_trues.append(target)\n",
        "        train_preds = np.hstack(train_preds)\n",
        "        train_trues = np.hstack(train_trues)\n",
        "        val_preds = np.hstack(val_preds)\n",
        "        val_trues = np.hstack(val_trues)\n",
        "        print(\n",
        "            f\"\"\"\n",
        "                best model performance is:\n",
        "                    train acc: {metrics.accuracy_score(train_trues, train_preds)}\n",
        "                    val acc: {metrics.accuracy_score(val_trues, val_preds)}\n",
        "\n",
        "                    train f1 score {metrics.f1_score(train_trues, train_preds)}\n",
        "                    val f1 score {metrics.f1_score(val_trues, val_preds)}\n",
        "\n",
        "                    train precision score {metrics.precision_score(train_trues, train_preds)}\n",
        "                    val precision score {metrics.precision_score(val_trues, val_preds)}\n",
        "\n",
        "                    train recall score {metrics.recall_score(train_trues, train_preds)}\n",
        "                    val recall score {metrics.recall_score(val_trues, val_preds)}\n",
        "\n",
        "                    num of pos prediction in training set {train_preds[train_preds == 1].shape[0]}\n",
        "                    num of neg prediction in training set {train_preds[train_preds == 0].shape[0]}\n",
        "                    num of pos prediction in val set {val_preds[val_preds == 1].shape[0]}\n",
        "                    num of neg prediction in val set {val_preds[val_preds == 0].shape[0]}\n",
        "            \"\"\"\n",
        "        )\n",
        "        print(\n",
        "            metrics.classification_report(val_trues, val_preds)\n",
        "            )"
      ],
      "id": "83bfc55a",
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52bcadaa"
      },
      "source": [
        "# hyperparams (change this e.g. change logit threshold for predictions)"
      ],
      "id": "52bcadaa"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3e87cfec"
      },
      "source": [
        "model = GNN(70, 32, 2)\n",
        "args = dict(\n",
        "    num_epochs = 40,\n",
        "    learning_rate = 2e-5,\n",
        "    device = \"cpu\",\n",
        "    val_size = .2,\n",
        "    ###########################\n",
        "    # not implemented\n",
        "    ###########################\n",
        "    threshold = 0 \n",
        ")\n",
        "\n",
        "args = argparse.Namespace(**args)\n",
        "trainer = Trainer(model, dataset, args)"
      ],
      "id": "3e87cfec",
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "eefdf313",
        "outputId": "1d05a98b-d36a-4f66-f4f5-515a1723ec01"
      },
      "source": [
        "model = trainer.train()"
      ],
      "id": "eefdf313",
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-70-bd7ca549ab20>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-68-a34328bf38b9>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m                     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-68-a34328bf38b9>\u001b[0m in \u001b[0;36m_train_step\u001b[0;34m(self, model, data)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_train_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shared_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-68-a34328bf38b9>\u001b[0m in \u001b[0;36m_shared_step\u001b[0;34m(self, model, data)\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_attr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_attr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_benchmark\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-67-2aa8d9672c5d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     31\u001b[0m         x = self.conv2(\n\u001b[1;32m     32\u001b[0m                     \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_attr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m                     \u001b[0medge_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m                     )\n\u001b[1;32m     35\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch_geometric/nn/conv/gcn_conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[1;32m    179\u001b[0m                     \u001b[0medge_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0;31m# propagate_type: (x: Tensor, edge_weight: OptTensor)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch_geometric/nn/dense/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;34m\"\"\"\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1846\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (29x70 and 32x32)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "be87e41a"
      },
      "source": [
        ""
      ],
      "id": "be87e41a",
      "execution_count": null,
      "outputs": []
    }
  ]
}